{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, linear_model, metrics, ensemble, naive_bayes, svm, tree, discriminant_analysis, neighbors, feature_selection\n",
    "from sklearn.linear_model import lasso_path\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "\n",
    "from scipy.stats import zscore, randint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('parkinsons.data', sep = ',',header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.It is always a good practice to eye-ball raw data to get a feel of the data in terms of number of structure of the file, number of attributes, types of attributes and a general idea of likely challenges in the dataset. (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute Information:\n",
    "\n",
    "Matrix column entries (attributes):\n",
    "\n",
    "* name - ASCII subject name and recording number\n",
    "* MDVP:Fo(Hz) - Average vocal fundamental frequency\n",
    "* MDVP:Fhi(Hz) - Maximum vocal fundamental frequency\n",
    "* MDVP:Flo(Hz) - Minimum vocal fundamental frequency\n",
    "* MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency\n",
    "* MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\n",
    "* NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n",
    "* status - Health status of the subject (one) - Parkinson's, (zero) - healthy\n",
    "* RPDE,D2 - Two nonlinear dynamical complexity measures\n",
    "* DFA - Signal fractal scaling exponent\n",
    "* spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Using univariate & bivariate analysis to check the individual attributes for their basic statistic such as central values, spread, tails etc. What are your observations? (15 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the above table:\n",
    "* For the variables MDVP:Fo(Hz), MDVP:Fhi(Hz), MDVP:Flo(Hz), MDVP:Jitter(%), MDVP:Jitter(Abs), MDVP:RAP, MDVP:PPQ, Jitter:DDP:\n",
    " * The mean value is greater than the median and the max value is > 75% of the value and this indicates a right tailed distribution or a positively skewed distribution\n",
    " * We have also plotted a histogram to visualize the same\n",
    "* For the Several measures of variation in amplitude: MDVP:Shimmer, MDVP:Shimmer(dB), Shimmer:APQ3, Shimmer:APQ5, MDVP:APQ, Shimmer:DDA\n",
    " * The mean value is greater than the median and they have a right tailed distribution or a positively skewed distribution\n",
    "* For NHR variable,the mean value is greater than the median and also the max value is very much greater than the 75% value which indicates a right tailed distribution or a positively skewed distribution\n",
    "* For HNR variable mean< median indicating a left tailed distribution.\n",
    "* Rest of the variables seems to have a positive skewed ditribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MDVP:Fo(Hz)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MDVP:Fhi(Hz)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MDVP:Flo(Hz)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MDVP:Jitter(%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MDVP:Jitter(Abs)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MDVP:RAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MDVP:PPQ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Jitter:DDP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MDVP:Shimmer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MDVP:Shimmer(dB)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Shimmer:APQ3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Shimmer:DDA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['NHR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['HNR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['DFA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['spread1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['PPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of the target variable : STATUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 195 records ,147 are having parkinsons and only 48 are healthy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the univariate analysis we found most of the attribute distribution are right tailed distribution (positively skewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, diag_kind='kde',hue='status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "corr = df.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask, 1)] = True\n",
    "sns.heatmap(corr,mask= mask,annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the plot is too big to visually analyse lets make it simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr().abs()\n",
    "corr[corr == 1] = 0\n",
    "corr_cols = corr.max().sort_values(ascending=False)\n",
    "display(corr_cols[corr_cols > 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Attibutes co-relation between the target variable Status\")\n",
    "df.drop([\"status\",\"name\"] , axis=1).apply(lambda x: x.corr(df.status)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Shimmer:DDA'], df['Shimmer:APQ3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['MDVP:RAP'], df['Jitter:DDP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['NHR'], df['HNR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots we are able to find a positive co-relation between Shimmer:DDA/Shimmer:APQ3 and also MDVP:RAP/Jitter:DDP and we are able to find a negative co-relation between NHR/HNR.\n",
    "\n",
    "From the bivariate analysis we found most of the attribute are having strong co-relations ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Split the dataset into training and test set in the ratio of 70:30 (Training:Test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"status\",\"name\"] , axis=1)\n",
    "X = X.apply(zscore)\n",
    "\n",
    "y = df['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, train_labels, test_labels = train_test_split(X, y, test_size=.30, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Create the model using “entropy” method of reducing the entropy and fit it to training data. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(criterion = 'entropy' ,random_state=7)\n",
    "dt_model.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Test the model on test data and what is the accuracy achieved. Capture the predicted values and do a crosstab. (7.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = dt_model.predict(test_set)\n",
    "\n",
    "print(\"The model training accuracy is :\",dt_model.score(train_set , train_labels))\n",
    "\n",
    "print(\"The models test accuracy is : \",dt_model.score(test_set , test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.crosstab(y_predict, test_labels, rownames=['Predicted'], colnames=['Actual'], margins=True)\n",
    "print(\"Cross Tab:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True positives >> the values which we predicted as parkinsons and the actual is also parkinsons->43\n",
    "* False positives (Type 1 error)>> the values which we predicted as parkinsons but the actual value is healthy->3\n",
    "* True Negatives -> the values which we predicted as healthy and the actual is also healthy->9\n",
    "* False Negatives (Type 2 error)>> the values which we predicted as healthy but the actual value is parkinsons->4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dt = classification_report(y_predict, test_labels)\n",
    "print(\"Classification report for Decision Tree Classifier\")\n",
    "print(report_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_labels, y_predict)\n",
    "dt_model_auc = auc(fpr, tpr)\n",
    "print(dt_model_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Use regularization parameters of max_depth, min_sample_leaf to recreate the model. What is the impact on the model accuracy? How does regularization help? (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularizing the max_depth parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"max_depth\": randint(1, 10), \n",
    "             \"criterion\": [\"entropy\"],\n",
    "             \"random_state\": [7]}\n",
    "dt=DecisionTreeClassifier()\n",
    "dt_model_cv = RandomizedSearchCV(dt, param_dist, cv = 5) \n",
    "dt_model_cv.fit(X, y) \n",
    "print(\"Tuned Decision Tree Parameters:\",dt_model_cv.best_params_) \n",
    "print(\"Best score is :\",dt_model_cv.best_score_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating decision tree model with regularized max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dt_model_depth = DecisionTreeClassifier(criterion = 'entropy',random_state =7,max_depth = 2)\n",
    "r_dt_model_depth.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_depth = r_dt_model_depth.predict(test_set)\n",
    "score_depth = r_dt_model_depth.score(test_set , test_labels)\n",
    "\n",
    "print(\"accuracy score after regularizing max_depth parameter\",score_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_depth = pd.crosstab(y_predict_depth, test_labels, rownames=['Predicted'], colnames=['Actual'], margins=True)\n",
    "print(\"Cross Tab:\")\n",
    "print(cm_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True positives >> the values which we predicted as parkinsons and the actual is also parkinsons->42\n",
    "* False positives (Type 1 error)>> the values which we predicted as parkinsons but the actual value is healthy->4\n",
    "* True Negatives -> the values which we predicted as healthy and the actual is also healthy->8\n",
    "* False Negatives (Type 2 error)>> the values which we predicted as healthy but the actual value is parkinsons->5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dt_depth = classification_report(y_predict_depth, test_labels)\n",
    "print(\"Classification report for Decision Tree Classifier\")\n",
    "print(report_dt_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_labels, y_predict_depth)\n",
    "dt_model_depth_auc = auc(fpr, tpr)\n",
    "print(dt_model_depth_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The max_depth regularization didnt improve the model score and the auc score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally regularization would help in reducing the variance which would end up in higher model scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularizing the min_samples_leaf parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"min_samples_leaf\": randint(1, 10), \n",
    "              \"criterion\": [\"entropy\"],\n",
    "             \"random_state\": [7]}\n",
    "dt=DecisionTreeClassifier()\n",
    "dt_model_cv = RandomizedSearchCV(dt, param_dist, cv = 5) \n",
    "dt_model_cv.fit(X, y) \n",
    "print(\"Tuned Decision Tree Parameters:\",dt_model_cv.best_params_) \n",
    "print(\"Best score is :\",dt_model_cv.best_score_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating decision tree model with regularized min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dt_model_leaf = DecisionTreeClassifier(criterion = 'entropy',random_state =7,min_samples_leaf = 2)\n",
    "r_dt_model_leaf.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_leaf = r_dt_model_leaf.predict(test_set)\n",
    "score_leaf = r_dt_model_leaf.score(test_set , test_labels)\n",
    "print(\"accuracy score after regularizing min_samples_leaf\",score_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_leaf = pd.crosstab(y_predict_leaf, test_labels, rownames=['Predicted'], colnames=['Actual'], margins=True)\n",
    "print(\"Cross Tab:\")\n",
    "print(cm_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True positives >> the values which we predicted as parkinsons and the actual is also parkinsons->42\n",
    "* False positives (Type 1 error)>> the values which we predicted as parkinsons but the actual value is healthy->2\n",
    "* True Negatives -> the values which we predicted as healthy and the actual is also healthy->10\n",
    "* False Negatives (Type 2 error)>> the values which we predicted as healthy but the actual value is parkinsons->5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dt_leaf = classification_report(y_predict_leaf, test_labels)\n",
    "print(\"Classification report for Decision Tree Classifier\")\n",
    "print(report_dt_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_labels, y_predict_leaf)\n",
    "dt_model_leaf_auc = auc(fpr, tpr)\n",
    "print(dt_model_leaf_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The regularization of min_samples_leaf parameter didn't improve the model score,but has improved the auc score a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularizing the min_samples_leaf and max_depth parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"max_depth\": randint(1, 10), \n",
    "              \"min_samples_leaf\": randint(1, 10), \n",
    "              \"criterion\": [\"entropy\"],\n",
    "             \"random_state\": [7]} \n",
    "dt=DecisionTreeClassifier()\n",
    "dt_model_cv = RandomizedSearchCV(dt, param_dist, cv = 5) \n",
    "dt_model_cv.fit(X, y) \n",
    "print(\"Tuned Decision Tree Parameters:\",dt_model_cv.best_params_) \n",
    "print(\"Best score is :\",dt_model_cv.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dt_model = DecisionTreeClassifier(criterion = 'entropy',random_state =7,max_depth = 3,min_samples_leaf = 1)\n",
    "r_dt_model.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_depth_leaf = r_dt_model.predict(test_set)\n",
    "score_depth_leaf = r_dt_model.score(test_set , test_labels)\n",
    "\n",
    "print(\"accuracy score after regularizing both the parametes\",score_depth_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_leaf_depth = pd.crosstab(y_predict_depth_leaf, test_labels, rownames=['Predicted'], colnames=['Actual'], margins=True)\n",
    "print(\"Cross Tab:\")\n",
    "print(cm_leaf_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True positives >> the values which we predicted as parkinsons and the actual is also parkinsons->45\n",
    "* False positives (Type 1 error)>> the values which we predicted as parkinsons but the actual value is healthy->3\n",
    "* True Negatives >> the values which we predicted as healthy and the actual is also healthy->9\n",
    "* False Negatives (Type 2 error)>> the values which we predicted as healthy but the actual value is parkinsons->2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dt_depth_leaf = classification_report(y_predict_depth_leaf, test_labels)\n",
    "print(\"Classification report for Decision Tree Classifier\")\n",
    "print(report_dt_depth_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_labels, y_predict_depth_leaf)\n",
    "dt_model_depth_leaf_auc = auc(fpr, tpr)\n",
    "print(dt_model_depth_leaf_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The regularization of min_samples_leaf and max_depth parameters improved the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall conclusion : Regularizing min_sample_leaf and Regularizing both parameters have improved the model, while Regularizing max_depth haven't improved model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Next implement the decision tree using Random Forest. What is the optimal number of trees that gives the best result? (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl = RandomForestClassifier(criterion = 'entropy',random_state=7)\n",
    "rfcl = rfcl.fit(train_set, train_labels)\n",
    "y_predict_rfcl = rfcl.predict(test_set)\n",
    "print(rfcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rfcl = pd.crosstab(y_predict_rfcl, test_labels, rownames=['Predicted'], colnames=['Actual'], margins=True)\n",
    "print(\"Cross Tab:\")\n",
    "print(cm_rfcl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True positives >> the values which we predicted as parkinsons and the actual is also parkinsons->45\n",
    "* False positives (Type 1 error)>> the values which we predicted as parkinsons but the actual value is healthy->3\n",
    "* True Negatives >> the values which we predicted as healthy and the actual is also healthy->9\n",
    "* False Negatives (Type 2 error)>> the values which we predicted as healthy but the actual value is parkinsons->2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_rfcl = classification_report(y_predict_rfcl, test_labels)\n",
    "print(\"Classification report for Decision Tree Classifier\")\n",
    "print(report_rfcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_labels, y_predict_rfcl)\n",
    "rfcl_model_auc = auc(fpr, tpr)\n",
    "print(rfcl_model_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the optimal number of trees which gives the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"n_estimators\": randint(1, 10), \n",
    "              \"criterion\": [\"entropy\"],\n",
    "             \"random_state\": [7]}\n",
    "rf_cv = RandomizedSearchCV(rfcl, param_dist, cv = 5) \n",
    "  \n",
    "rf_cv.fit(X, y) \n",
    "print(\"Tuned Random forest Parameters:\",rf_cv.best_params_)\n",
    "print(\"Best score is \",rf_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized random forest with optimal number of trees¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl = RandomForestClassifier(criterion = 'entropy',n_estimators =7,random_state=7)\n",
    "r_rfcl = rfcl.fit(train_set, train_labels)\n",
    "print(r_rfcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_r_rfcl = rfcl.predict(test_set)\n",
    "print(\"testscore\",rfcl.score(test_set , test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_r_rfcl = pd.crosstab(y_predict_r_rfcl, test_labels, rownames=['Predicted'], colnames=['Actual'], margins=True)\n",
    "print(\"Cross Tab:\")\n",
    "print(cm_rfcl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True positives >> the values which we predicted as parkinsons and the actual is also parkinsons->45\n",
    "* False positives (Type 1 error)>> the values which we predicted as parkinsons but the actual value is healthy->3\n",
    "* True Negatives >> the values which we predicted as healthy and the actual is also healthy->9\n",
    "* False Negatives (Type 2 error)>> the values which we predicted as healthy but the actual value is parkinsons->2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_r_rfcl = classification_report(y_predict_r_rfcl, test_labels)\n",
    "print(\"Classification report for Decision Tree Classifier\")\n",
    "print(report_r_rfcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_labels, y_predict_r_rfcl)\n",
    "r_rfcl_model_auc = auc(fpr, tpr)\n",
    "print(r_rfcl_model_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* The regularization parameters of max_depth, min_sample_leaf using randomizedsearchCV, we found a slight improvement in model performance.(model score before regularizing parameters/model score after regularizing parameters = 0.88/0.91 and AUC of decision tree before regularizing': 0.83, 'AUC of decision tree after regularizing': 0.85 the best value of params are max_depth = 3,min_samples_leaf = 1)and the AUC showed a little bit of improvement\n",
    "\n",
    "* Model score and auc score after regularizing min_samples_leaf param:0.8813559322033898,0.8324468085106383\n",
    "\n",
    "* Model score and auc score after regularizing max_depth param:0.847457627118644,0.7801418439716312\n",
    "\n",
    "* Implementing the decision tree using Random Forest and found 7 is the optimal number of trees that gives the best result and the model score we got is 0.91 and AUC is 85"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
